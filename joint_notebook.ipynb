{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "#visualization libraries\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import plotly.graph_objs as go\r\n",
    "import plotly.express as px\r\n",
    "\r\n",
    "#machine learning libraries\r\n",
    "from xgboost import XGBClassifier\r\n",
    "\r\n",
    "#model selection\r\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\r\n",
    "\r\n",
    "#metrics\r\n",
    "from sklearn.metrics import confusion_matrix,plot_confusion_matrix,precision_score,recall_score,f1_score,balanced_accuracy_score,accuracy_score\r\n",
    "from sklearn import metrics\r\n",
    "\r\n",
    "pd.set_option(\"display.max_columns\",None)\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.model_selection import StratifiedKFold\r\n",
    "\r\n",
    "# Preprocessing\r\n",
    "from sklearn import preprocessing\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "\r\n",
    "# Pipeline\r\n",
    "from sklearn import pipeline\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_td = df # Making copy of data frame "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exploratory Data Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see the basic statistics of our data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.describe().T"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we have 9 categorical features. The rest are ordinal or continuous values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's look at the categorical columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "categories = df.select_dtypes([object]).columns\r\n",
    "print(categories)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.select_dtypes([object]).head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's look at the unique values of each category."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in df.select_dtypes([object]).columns:\r\n",
    "    print(i,\":\",df[i].unique())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "| Feature | Comment |\n",
    "| --- | --- |\n",
    "| **Attrition** | This is the label of interest. We will convert this to a binary variable {1: yes, 0: no} |\n",
    "| **BusinessTravel** | We will convert this to an ordinal variable {0: Non-Travel, 1: Travel_Rarely, 2: Travel_Frequently} |\n",
    "| **Department** | This is purely categorical, so we will have to one-hot encode or convert to a dummy variable |\n",
    "| **EducationField** | This is purely categorical, so we will have to one-hot encode or convert to a dummy variable |\n",
    "| **Gender** | There are only 2 values in the dataset, so we can convert this to a binary variable. This is legally protected data, so we have to be careful that using this feature does not lead to any forms of gender discrimination. |\n",
    "| **JobRole** | This is purely categorical, so we will have to one-hot encode or convert to a dummy variable. This category has a decent number of values. By converting it, we are increasing our dimensionality by 9. This could lead to the curse of dimensionality. |\n",
    "| **MaritalStatus** | Categorical, but one could make the case to make it ordinal. If we made it ordinal, then the mapping would be {0: Single, 1: Married, 2: Divorced}. Again, we have to be careful as using this information to make a hiring decision would be illegal. |\n",
    "| **Over18** | This feature only has 1 value, so we will drop it. |\n",
    "| **OverTime** | We will convert this to a binary variable {0: No, 1: Yes} |"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For now we are transforming the ordinal features into their numeric typed columns and drop the constant column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = df.drop(\"Over18\",axis=1)\r\n",
    "df[\"Attrition\"] = df[\"Attrition\"].map({\"No\": 0, \"Yes\": 1})\r\n",
    "df[\"BusinessTravel\"] = df[\"BusinessTravel\"].map({\"Non-Travel\": 0, \"Travel_Rarely\": 1,\"Travel_Frequently\": 2})\r\n",
    "df[\"OverTime\"] = df[\"OverTime\"].map({\"No\": 0, \"Yes\": 1})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's look at the numerical columns."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "numerical = df.select_dtypes([np.int64]).columns\r\n",
    "print(numerical)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.select_dtypes([np.int64]).head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the numerical features, we have 2 columns that have a constant value: StandardHours and EmployeeCount. We can drop those columns."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(df[\"StandardHours\"].unique())\r\n",
    "print(df[\"EmployeeCount\"].unique())\r\n",
    "df = df.drop([\"StandardHours\",\"EmployeeCount\"],axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "numerical = df.select_dtypes([np.int64]).columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corr = df[numerical].corr()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trace = go.Heatmap(\r\n",
    "    z=np.abs(corr.values),\r\n",
    "    x=corr.columns.values,\r\n",
    "    y=corr.columns.values,\r\n",
    "    colorscale=\"greys\"\r\n",
    ")\r\n",
    "fig = go.Figure(data=trace)\r\n",
    "fig.update_layout(\r\n",
    "    title=\"Interactive correlation heatmap of numerical features\",\r\n",
    "    autosize=False,\r\n",
    "    width=750,\r\n",
    "    height=750\r\n",
    ")\r\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The only features that have a high correlation are MonthlyIncome and JobLevel."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Attrition is not strongly correlated with any other feature. Its highest correlation is with OverTime, and it is not that high."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corr[\"Attrition\"][np.abs(corr[\"Attrition\"]) > 0.1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = px.histogram(df,x=\"BusinessTravel\",color=\"Attrition\")\r\n",
    "fig.update_layout(\r\n",
    "    autosize=False,\r\n",
    "    title=\"Interactive histogram of BusinessTravel\"\r\n",
    ")\r\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tejas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EDA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_td.describe().T"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Dropped below columns (EmployeeCount,Over18,StandardHours) because it's only has one value for all rows. Also dropping EmployeeNumber."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_td.drop(columns=['EmployeeCount', 'Over18', 'StandardHours','EmployeeNumber'], inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dfColumns = []\r\n",
    "for i in df_td.columns:\r\n",
    "    dfColumns.append([i, df_td[i].nunique(), df_td[i].drop_duplicates().values])\r\n",
    "pd.DataFrame(dfColumns, columns = ['Features', 'Unique Number', 'Values'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Number 1 is Yes, means employee moves out of company and number 0 is No, means stay."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_td['Attrition'] = np.where(df_td['Attrition'] == 'Yes', 1, 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_td[\"Attrition\"].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_td['Attrition'].value_counts()/df_td.shape[0]*100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Correlation Plot\r\n",
    "f, ax = plt.subplots(figsize=(18, 14))\r\n",
    "corr = df_td.corr()\r\n",
    "hm = sns.heatmap(round(corr,2), annot=True, ax=ax, cmap=\"coolwarm\",fmt='.2f', linewidths=.05)\r\n",
    "f.subplots_adjust(top=0.95)\r\n",
    "t= f.suptitle('HR-Employee-Attrition - Correlation Heatmap', fontsize=16)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### We can see from the correlation plot that Attrition does not have strong correlation with any other variables. We can also see from the correlation plot that only few variables have relatively strong correlation. Job Level and Monthly Income has highest correlation of 0.95. \n",
    "\n",
    "#### Some other correlated variables are as follows: \n",
    "- TotalWorkingYears and Monthly Income (0.78)\n",
    "- Age and TotalWorkingYears (0.68)\n",
    "- YearsAtComapny and YearsWithCurrManager (0.77)\n",
    "- YearsInCurrentRole and YearsWithCurrManager (0.71)\n",
    "- YearsInCurrentRole and YearsAtCompany (0.76)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize=(10, 6))\r\n",
    "(df_td[df_td['Attrition'] == 1]['Age']).hist(bins=30, color='blue', linewidth=1.0,alpha=0.5, label = 'Attrition=1',\r\n",
    "              xlabelsize=8, ylabelsize=8, grid=True)  \r\n",
    "(df_td[df_td['Attrition'] == 0]['Age']).hist(bins=30, color='red', linewidth=1.0,alpha=0.5,label = 'Attrition=0',\r\n",
    "              xlabelsize=8, ylabelsize=8, grid=True)  \r\n",
    "plt.legend()\r\n",
    "plt.xlabel(\"Age\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Younger employees were more likely to attrition "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=[11,7])\r\n",
    "ax = sns.countplot(x=\"JobLevel\", hue=\"Attrition\", data=df_td, palette=\"Set1\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "round(df_td[[\"JobLevel\",\"Attrition\"]].groupby([\"JobLevel\",\"Attrition\"]).size().groupby(level=0).apply(lambda x: x/x.sum()),2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Low job level has higher attrition rate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=[11,7])\r\n",
    "ax = sns.countplot(x=\"Department\", hue=\"Attrition\", data=df_td, palette=\"Set1\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Doing some math\r\n",
    "print(df_td[df_td['Attrition'] == 1]['Department'].value_counts())\r\n",
    "print(df_td[df_td['Attrition'] == 0]['Department'].value_counts())\r\n",
    "print(df_td[df_td['Department'] == 'Research & Development'].count().unique())\r\n",
    "print(df_td[df_td['Department'] == 'Sales'].count().unique())\r\n",
    "print(df_td[df_td['Department'] == 'Human Resources'].count().unique())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "round(df_td[[\"Department\",\"Attrition\"]].groupby([\"Department\",\"Attrition\"]).size().groupby(level=0).apply(lambda x: x/x.sum()),2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Sales and HR have higher attrition rates compared to research and development  department"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=[11,7])\r\n",
    "ax = sns.countplot(x=\"Gender\", hue=\"Attrition\", data=df_td, palette=\"Set1\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Doing Some math\r\n",
    "print(df_td[df_td['Attrition'] == 1]['Gender'].value_counts())\r\n",
    "print(df_td[df_td['Attrition'] == 0]['Gender'].value_counts())\r\n",
    "print(df_td[df_td['Gender'] == 'Male'].count().unique())\r\n",
    "print(df_td[df_td['Gender'] == 'Female'].count().unique())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "round(df_td[[\"Gender\",\"Attrition\"]].groupby([\"Gender\",\"Attrition\"]).size().groupby(level=0).apply(lambda x: x/x.sum()),2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Males were found to be more likely to attrition  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize=(10, 6))\r\n",
    "(df_td[df_td['Attrition'] == 1]['MonthlyIncome']).hist(bins=30, color='blue', linewidth=1.0,alpha=0.5, label = 'Attrition=1',\r\n",
    "              xlabelsize=8, ylabelsize=8, grid=True)  \r\n",
    "(df_td[df_td['Attrition'] == 0]['MonthlyIncome']).hist(bins=30, color='red', linewidth=1.0,alpha=0.5,label = 'Attrition=0',\r\n",
    "              xlabelsize=8, ylabelsize=8, grid=True)  \r\n",
    "plt.legend()\r\n",
    "plt.xlabel(\"MonthlyIncome\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Attrition rate is higher at lower monthly income "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize=(10, 6))\r\n",
    "(df_td[df_td['Attrition'] == 1]['YearsAtCompany']).hist(bins=30, color='blue', linewidth=1.0,alpha=0.5, label = 'Attrition=1',\r\n",
    "              xlabelsize=8, ylabelsize=8, grid=True)  \r\n",
    "(df_td[df_td['Attrition'] == 0]['YearsAtCompany']).hist(bins=30, color='red', linewidth=1.0,alpha=0.5,label = 'Attrition=0',\r\n",
    "              xlabelsize=8, ylabelsize=8, grid=True)  \r\n",
    "plt.legend()\r\n",
    "plt.xlabel(\"YearsAtCompany\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=[22,7])\r\n",
    "ax = sns.countplot(x=\"JobRole\", hue=\"Attrition\", data=df_td, palette=\"Set1\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "round(df_td[[\"JobRole\",\"Attrition\"]].groupby([\"JobRole\",\"Attrition\"]).size().groupby(level=0).apply(lambda x: x/x.sum()),2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Sales Representative and Lab Technicain have higher attrition rate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=[11,7])\r\n",
    "ax = sns.countplot(x=\"MaritalStatus\", hue=\"Attrition\", data=df_td, palette=\"Set1\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "round(df_td[[\"MaritalStatus\",\"Attrition\"]].groupby([\"MaritalStatus\",\"Attrition\"]).size().groupby(level=0).apply(lambda x: x/x.sum()),2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Employees who are single have higher rates of attrition compared to married and divorced workers  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=[11,7])\r\n",
    "ax = sns.countplot(x=\"BusinessTravel\", hue=\"Attrition\", data=df_td, palette=\"Set1\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Employees who travel frequently have higher attrition rates than who travel rarely or didn’t travel at all "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "round(df_td[[\"BusinessTravel\",\"Attrition\"]].groupby([\"BusinessTravel\",\"Attrition\"]).size().groupby(level=0).apply(lambda x: x/x.sum()),2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tejas Model 1 -  AdaBoost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cat_feats =  ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'OverTime']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Converting categorical variables to dummy variables\r\n",
    "df_new = pd.get_dummies(df_td, columns = cat_feats,)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_new.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparing data from machine learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = df_new.drop('Attrition', axis = 1)\r\n",
    "y = df_new['Attrition']\r\n",
    "X.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Trai, Validation Split\r\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y,stratify=y, test_size=0.30, random_state=2021)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Standardization of the data\r\n",
    "ss = StandardScaler()\r\n",
    "ss.fit(X_train)\r\n",
    "X_train = ss.transform(X_train)\r\n",
    "X_val = ss.transform(X_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AdaBoost model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "adabc = AdaBoostClassifier()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "adabc.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred_adabc = adabc.predict(X_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Validation accuracy\r\n",
    "metrics.accuracy_score(y_val, y_pred_adabc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pred_train_adabc=adabc.predict(X_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Training accuracy\r\n",
    "metrics.accuracy_score(y_train, pred_train_adabc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Adaboost\\n',metrics.classification_report(y_val, y_pred_adabc))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Confusion Matrix:Adaboost\\n')\r\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, y_pred_adabc).ravel()\r\n",
    "print(metrics.confusion_matrix(y_val, y_pred_adabc))\r\n",
    "recall_score = metrics.recall_score(y_val, y_pred_adabc)\r\n",
    "specificity = tn / (tn+fp)\r\n",
    "precision_score = metrics.precision_score(y_val, y_pred_adabc)\r\n",
    "accuracy = metrics.accuracy_score(y_val, y_pred_adabc)\r\n",
    "balanced_accuracy = metrics.balanced_accuracy_score(y_val, y_pred_adabc)\r\n",
    "f1_score = metrics.f1_score(y_val, y_pred_adabc)\r\n",
    "print(\"\\nMetrics on test data\")\r\n",
    "print('Recall Score :', round(recall_score,2))\r\n",
    "print('Specificity :', round(specificity,2))\r\n",
    "print('Precision Score :', round(precision_score,2))\r\n",
    "print('Accuracy:', round(accuracy,2))\r\n",
    "print('Balanced Accuracy:', round(balanced_accuracy,2))\r\n",
    "print('F1 Score :', round(f1_score,2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Apply cross validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cv_ab = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "adabc = AdaBoostClassifier()\r\n",
    "scores = cross_val_score(adabc, X=X_train, y=y_train, scoring='accuracy', cv=cv_ab, n_jobs=1, )\r\n",
    "print('CV accuracy scores: %s' % scores)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adaboost model - pipeline and gridsearch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def print_results(results):\r\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\r\n",
    "\r\n",
    "    means = results.cv_results_['mean_test_score']\r\n",
    "    stds = results.cv_results_['std_test_score']\r\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\r\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ss = preprocessing.StandardScaler()\r\n",
    "adabc = AdaBoostClassifier()\r\n",
    "\r\n",
    "steps = [('ss', ss),\r\n",
    "         ('classifier', adabc)]\r\n",
    "\r\n",
    "parameters = {\r\n",
    "    'classifier__n_estimators': [50,100,200,300],\r\n",
    "    'classifier__learning_rate': [0.1,0.2,1,2],\r\n",
    "}\r\n",
    "pipe = pipeline.Pipeline(steps)\r\n",
    "\r\n",
    "cv_pipe_ab = GridSearchCV(pipe, parameters, cv=cv_ab, n_jobs=-1, scoring = 'accuracy')\r\n",
    "cv_pipe_ab.fit(X_train, y_train)\r\n",
    "\r\n",
    "print_results(cv_pipe_ab)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_estimator_ab_pipe = cv_pipe_ab.best_estimator_\r\n",
    "best_estimator_ab_pipe"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pred_pipe_ab = best_estimator_ab_pipe.predict(X_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Testing # Validation Accuracy\r\n",
    "metrics.accuracy_score(y_val, pred_pipe_ab)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Training\r\n",
    "pred_train_pipe_ab=best_estimator_ab_pipe.predict(X_train)\r\n",
    "metrics.accuracy_score(y_train, pred_train_pipe_ab)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Adaboost with Hyperparamter Tuning\\n',metrics.classification_report(y_val, pred_pipe_ab))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('\\nConfusion Matrix: Adaboost with Hyperparamter Tuning\\n')\r\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, pred_pipe_ab).ravel()\r\n",
    "print(metrics.confusion_matrix(y_val, pred_pipe_ab))\r\n",
    "recall_score = metrics.recall_score(y_val, pred_pipe_ab)\r\n",
    "specificity = tn / (tn+fp)\r\n",
    "precision_score = metrics.precision_score(y_val, pred_pipe_ab)\r\n",
    "accuracy = metrics.accuracy_score(y_val, pred_pipe_ab)\r\n",
    "balanced_accuracy = metrics.balanced_accuracy_score(y_val, pred_pipe_ab)\r\n",
    "f1_score = metrics.f1_score(y_val, pred_pipe_ab)\r\n",
    "\r\n",
    "print(\"\\nMetrics on test data\")\r\n",
    "print('Recall Score :', round(recall_score,2))\r\n",
    "print('Specificity :', round(specificity,2))\r\n",
    "print('Precision Score :', round(precision_score,2))\r\n",
    "print('Accuracy:', round(accuracy,2))\r\n",
    "print('Balanced Accuracy:', round(balanced_accuracy,2))\r\n",
    "print('F1 Score :', round(f1_score,2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tejas Model 2 - Support vector machine Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fit RBF Kernel SVM Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.svm import SVC"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "svc_rbf = SVC(kernel ='rbf')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "svc_rbf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cv_svc = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "svc_rbf.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Validation # Testing\r\n",
    "y_pred_svc_rbf = svc_rbf.predict(X_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "metrics.accuracy_score(y_val, y_pred_svc_rbf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Train\r\n",
    "pred_train_svc_rbf=svc_rbf.predict(X_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Train\r\n",
    "metrics.accuracy_score(y_train, pred_train_svc_rbf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('SVC-Fit RBF Kernel SVM Classifier\\n',metrics.classification_report(y_val, y_pred_svc_rbf))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('\\nConfusion Matrix: SVC-Fit RBF Kernel SVM Classifier\\n')\r\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, y_pred_svc_rbf).ravel()\r\n",
    "print(metrics.confusion_matrix(y_val, y_pred_svc_rbf))\r\n",
    "recall_score = metrics.recall_score(y_val, y_pred_svc_rbf)\r\n",
    "specificity = tn / (tn+fp)\r\n",
    "precision_score = metrics.precision_score(y_val, y_pred_svc_rbf)\r\n",
    "accuracy = metrics.accuracy_score(y_val, y_pred_svc_rbf)\r\n",
    "balanced_accuracy = metrics.balanced_accuracy_score(y_val, y_pred_svc_rbf)\r\n",
    "f1_score = metrics.f1_score(y_val, y_pred_svc_rbf)\r\n",
    "\r\n",
    "print(\"\\nMetrics on test data\")\r\n",
    "print('Recall Score :', round(recall_score,2))\r\n",
    "print('Specificity :', round(specificity,2))\r\n",
    "print('Precision Score :', round(precision_score,2))\r\n",
    "print('Accuracy:', round(accuracy,2))\r\n",
    "print('Balanced Accuracy:', round(balanced_accuracy,2))\r\n",
    "print('F1 Score :', round(f1_score,2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Grid Search # Hyperparamter Tuning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Code\r\n",
    "parameters = {\r\n",
    "    'gamma': [1,0.1,0.01,0.001,0.0001],\r\n",
    "    'C': [1,10,100,1000]\r\n",
    "}\r\n",
    "svc_rbf_gs = GridSearchCV(svc_rbf,parameters,cv=cv_svc)\r\n",
    "svc_rbf_gs.fit(X_train, y_train)\r\n",
    "print_results(svc_rbf_gs)\r\n",
    "\r\n",
    "print('Best score for data:', svc_rbf_gs.best_score_)\r\n",
    "print('Best C:',svc_rbf_gs.best_estimator_.C) \r\n",
    "print('Best Gamma:',svc_rbf_gs.best_estimator_.gamma)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_estimator_svc_gs = svc_rbf_gs.best_estimator_\r\n",
    "best_estimator_svc_gs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Validation Predict\r\n",
    "y_pred_svc_rbf_gs = best_estimator_svc_gs.predict(X_val)\r\n",
    "# Training Predict\r\n",
    "pred_train_svc_rbf_gs= best_estimator_svc_gs.predict(X_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Testing Accuracy Score # Validation\r\n",
    "metrics.accuracy_score(y_val, y_pred_svc_rbf_gs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Training Accuracy Score\r\n",
    "metrics.accuracy_score(y_train, pred_train_svc_rbf_gs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('SVC-Fit RBF Kernel SVM Classifier with tuning\\n',metrics.classification_report(y_val, y_pred_svc_rbf_gs))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('\\nConfusion Matrix:SVC-Fit RBF Kernel SVM Classifier with tuning-Grid Search')\r\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, y_pred_svc_rbf_gs).ravel()\r\n",
    "print(metrics.confusion_matrix(y_val, y_pred_svc_rbf_gs))\r\n",
    "recall_score = metrics.recall_score(y_val, y_pred_svc_rbf_gs)\r\n",
    "specificity = tn / (tn+fp)\r\n",
    "precision_score = metrics.precision_score(y_val, y_pred_svc_rbf_gs)\r\n",
    "accuracy = metrics.accuracy_score(y_val, y_pred_svc_rbf_gs)\r\n",
    "balanced_accuracy = metrics.balanced_accuracy_score(y_val, y_pred_svc_rbf_gs)\r\n",
    "f1_score = metrics.f1_score(y_val, y_pred_svc_rbf_gs)\r\n",
    "\r\n",
    "print(\"\\nMetrics on test data\")\r\n",
    "print('Recall Score :', round(recall_score,2))\r\n",
    "print('Specificity :', round(specificity,2))\r\n",
    "print('Precision Score :', round(precision_score,2))\r\n",
    "print('Accuracy:', round(accuracy,2))\r\n",
    "print('Balanced Accuracy:', round(balanced_accuracy,2))\r\n",
    "print('F1 Score :', round(f1_score,2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def training_run_classification(model,parameters,X_train,y_train,X_val,y_val,scoring=None):\r\n",
    "    cv = GridSearchCV(model,parameters,cv=4,n_jobs=-1,scoring=scoring)\r\n",
    "    cv.fit(X_train,y_train)\r\n",
    "    model = cv.best_estimator_\r\n",
    "    print(cv.best_params_)\r\n",
    "    pred = model.predict(X_val)\r\n",
    "    cm = confusion_matrix(y_val,pred)\r\n",
    "    acc = accuracy_score(y_val,pred)\r\n",
    "    balanced_accuracy = balanced_accuracy_score(y_val,pred)\r\n",
    "    precision = precision_score(y_val,pred)\r\n",
    "    recall = recall_score(y_val,pred)\r\n",
    "    f1 = f1_score(y_val,pred)\r\n",
    "    specificity = cm[0,0]/np.sum(cm[0])\r\n",
    "    \r\n",
    "    print(f\"Accuracy: {acc}\")\r\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy}\")\r\n",
    "    print(f\"Precision: {precision}\")\r\n",
    "    print(f\"Recall: {recall}\")\r\n",
    "    print(f\"f1: {f1}\")\r\n",
    "    print(f\"Specificity: {specificity}\")\r\n",
    "    plot_confusion_matrix(model,X_val,y_val)\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ADABoost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "parameters = {\r\n",
    "    \"n_estimators\": [5,25,100,200],\r\n",
    "    \"max_depth\": [None,2,5,10,20],\r\n",
    "    \"learning_rate\": [0.1,1,10],\r\n",
    "    \"booster\": [\"gbtree\",\"gblinear\",\"dart\"],\r\n",
    "    \"tree_method\": [\"exact\",\"approx\",\"hisat\"],\r\n",
    "    \"n_jobs\": [-1],\r\n",
    "    \"reg_alpha\": [0.1,1,10],\r\n",
    "    \"reg_lambda\": [0.1,1,10],\r\n",
    "    \"scale_pos_weight\": [3],\r\n",
    "    \"random_state\": [1]\r\n",
    "}\r\n",
    "\r\n",
    "xgb = training_run_classification(XGBClassifier(),parameters,x_train,y_train,x_test,y_test,scoring=\"balanced_accuracy\")"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9563a1eb5ea6998bda3b999fe9e3157bb5d5b789b415171fc389ba85846d4b73"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('DSC540': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}